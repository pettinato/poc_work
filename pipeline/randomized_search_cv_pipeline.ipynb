{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC on using Sklearn pipeline with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from joblib import dump, load\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import tempfile\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy 1.16.4\n",
      "Pandas 0.24.2\n",
      "Scikit-Learn 0.21.2\n",
      "XGBoost 0.90\n"
     ]
    }
   ],
   "source": [
    "print(\"NumPy\", np.__version__)\n",
    "print(\"Pandas\", pd.__version__)\n",
    "print(\"Scikit-Learn\", sklearn.__version__)\n",
    "print(\"XGBoost\", xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(432)\n",
    "obs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2  target_class        f3         c1          c2\n",
      "0  0.903661  0.896010  0.589950         False -0.547680  category1  cat_type_2\n",
      "1  0.987273  0.851603  0.208817          True  0.622484  category2  cat_type_2\n"
     ]
    }
   ],
   "source": [
    "population_df = (\n",
    "    # Make columns of noise\n",
    "    pd.DataFrame(np.random.rand(obs, 3), columns=[f\"f{i}\" for i in range(3)])\n",
    "    .assign(target_class=np.random.rand(obs, 1) > 0.5)\n",
    "    # Make columns that can help predict the target\n",
    "    .assign(f3=lambda p_df: p_df.target_class.apply(lambda tc: tc + np.random.standard_normal()))\n",
    "    .assign(c1=['category1', 'category2', 'category3', 'category4'] * int(obs/4))\n",
    "    .assign(c2=['cat_type_2', 'cat_type_2'] * int(obs/2))\n",
    ")\n",
    "print(population_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['c1', 'c2']\n",
    "numeric_features = ['f0', 'f1', 'f2', 'f3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    population_df.drop(columns=['target_class']), population_df.target_class, test_size=0.1, random_state=43223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplierTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Multiply the numeric cols by a mean of the columns.  Just a test\"\"\"\n",
    "\n",
    "    def __init__(self, numeric_cols):\n",
    "        self.numeric_cols = numeric_cols\n",
    "\n",
    "    def fit(self, X_df, _):\n",
    "        self.multiple = population_df[numeric_features[2:]].mean().mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_df[self.numeric_cols] = X_df[self.numeric_cols] * self.multiple\n",
    "        return X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the pipeline and the RandomizedSearch\n",
    "pipeline_test_1 = make_pipeline(\n",
    "    MultiplierTransformer(numeric_features[2:]),\n",
    "    ColumnTransformer(\n",
    "        remainder='passthrough',\n",
    "        transformers=[\n",
    "            ('impute', Pipeline(steps=[('input', SimpleImputer(strategy='mean'))]), numeric_features[:2]),\n",
    "            ('cat', Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features),\n",
    "    ]),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=4431)\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"randomforestclassifier__max_depth\": sp_randint(1, 21),\n",
    "    \"randomforestclassifier__max_features\": sp_randint(1, X_train.shape[1] + 1),\n",
    "    \"randomforestclassifier__min_samples_split\": sp_randint(1, 1000),\n",
    "    \"randomforestclassifier__bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "pipeline_test_1_search_model = RandomizedSearchCV(\n",
    "    pipeline_test_1, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=3,\n",
    "    cv=3,\n",
    "    iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.09 s, sys: 273 ms, total: 3.37 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "# Not sure where the SettingWithCopyWarning is coming from so use capture\n",
    "\n",
    "out_file = tempfile.NamedTemporaryFile()\n",
    "\n",
    "print(\"Fitting Model\")\n",
    "pipeline_test_1_search_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Saving model to file {out_file.name}\")\n",
    "dump(pipeline_test_1_search_model, out_file.name)\n",
    "\n",
    "print(f\"Pulling model from file {out_file.name}\")\n",
    "pipeline_test_1_search_model = load(out_file.name)\n",
    "\n",
    "predictions = pipeline_test_1_search_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Setup the pipeline and the RandomizedSearch\n",
    "pipeline_test_1 = make_pipeline(\n",
    "    MultiplierTransformer(numeric_features[2:]),\n",
    "    ColumnTransformer(\n",
    "        remainder='passthrough',\n",
    "        transformers=[\n",
    "            ('impute', Pipeline(steps=[('input', SimpleImputer(strategy='mean'))]), numeric_features[:2]),\n",
    "            ('cat', Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features),\n",
    "    ]),\n",
    "    XGBClassifier(n_estimators=10, random_state=432, n_jobs=-1)\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'xgbclassifier__min_child_weight': sp_randint(1, 10),\n",
    "    'xgbclassifier__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'xgbclassifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'xgbclassifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'xgbclassifier__max_depth': sp_randint(1, 21),\n",
    "    'xgbclassifier__num_feature': sp_randint(1, X_train.shape[1] + 1)\n",
    "}\n",
    "\n",
    "print(\"Configuring RandomSearch\")\n",
    "pipeline_test_1_search_model = RandomizedSearchCV(\n",
    "    pipeline_test_1, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=3,\n",
    "    cv=3,\n",
    "    iid=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 13 ms, total: 2.05 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%capture\n",
    "# Not sure where the SettingWithCopyWarning is coming from so use capture\n",
    "\n",
    "out_file = tempfile.NamedTemporaryFile()\n",
    "\n",
    "print(\"Fitting Model\")\n",
    "pipeline_test_1_search_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Saving model to file {out_file.name}\")\n",
    "dump(pipeline_test_1_search_model, out_file.name)\n",
    "\n",
    "print(f\"Pulling model from file {out_file.name}\")\n",
    "pipeline_test_1_search_model = load(out_file.name)\n",
    "\n",
    "\n",
    "predictions = pipeline_test_1_search_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
